{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](brain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseau profond\n",
    "## Mise en situation\n",
    "Toujours salarié à la poste, préposé aux algorithmes de reconnaissance des codes postaux :)\n",
    "\n",
    "90% c'est bien, tentons de faire mieux. Si passer d'un modèle logistique (1 couche) à un réseau de neurones tel qu'on la vu (2 couches) a grandement amélioré le modèle, est-ce qu'on ne pourrait pas faire encore mieux avec des couches en plus ?\n",
    "\n",
    "## L'apprentissage profond\n",
    "### Le principe\n",
    "Le principe du _Deep Learning_, c'est d'entrer plus en profondeur dans l'apprentissage. Ajouter des couches de réseau notamment.\n",
    "\n",
    "L'idée est la suivante - pour de la reconnaissance d'images : une première couche va détecter des patterns simples (des lignes par exemple), une seconde couche va détecter des patterns plus complexes qui combinent les premiers (des courbes par exemple), une troisième va mixer les précédents pour reconnaître des formes, etc...\n",
    "\n",
    "### Définition formelle des couches\n",
    "On appelle généralement les entrées la première couche, et la sortie la dernière couche.\n",
    "Toutes les couches intermédiaires sont les couches cachées (_hidden layers_).\n",
    "\n",
    "Autrement dit, dans le modèle précédent, il s'agissait sémantiquement parlant d'un réseau à trois couches : l'entrée (qui faisait 28x28), la couche intermédiaire (variable) et la sortie (taille 10).\n",
    "\n",
    "### Dérivation et propagation du gradient\n",
    "Le calcul de la dérivée va se faire comme précédemment. En gros, si on a une entrée $A_{n-1}$, des paramètres $W_{n}$ et $b_{n}$, et une fonction d'activation $a()$, on a:\n",
    "\n",
    "* Passe en avant :\n",
    "\n",
    "$Z_{n} = W_{n}.A_{n-1} + b_{n}\\\\\n",
    "A_{n} = a(Z_{n})$\n",
    "\n",
    "* Passe en arrière : avec en plus $dA_{n}$\n",
    "\n",
    "$dZ_{n} = a'(Z_{n}) * dA_{n}\\\\\n",
    "dW_{n} = dZ.A_{n-1}^T\\\\\n",
    "db_{n} = \\sum{dZ}\\\\\n",
    "dA_{n-1} = W_{n}^T.dZ$\n",
    "\n",
    "## Implémentation\n",
    "Pour implémenter ça, on va procéder de la manière suivante:\n",
    "1. On calcule les différents Z et A pour chaque couche. On gardera les résultats du calcul pour la marche arrière.\n",
    "2. On revient en marche arrière, couche par couche aussi\n",
    "3. On applique la descente de gradient\n",
    "\n",
    "### Les fonctions\n",
    "On commence par implémenter les différentes fonctions. On va aussi en faire un dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les différentes fonctions\n",
    "def sigmoid(x) : return 1 / (1 + np.exp(-x))\n",
    "def tanh(x): return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "def relu(x): return np.maximum(x, 0)\n",
    "\n",
    "act_functions = {'sigmoid': sigmoid, 'tanh' : tanh, 'relu' : relu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les dérivées\n",
    "\n",
    "Et maintenant les dérivées de ces fonctions. On en fera aussi un dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leurs dérivées\n",
    "def d_sigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def d_tanh(x):\n",
    "    t = tanh(x)\n",
    "    return 1 - t**2\n",
    "\n",
    "def d_relu(x):\n",
    "    return x > 0\n",
    "\n",
    "act_derivates = {'sigmoid': d_sigmoid, 'tanh' : d_tanh, 'relu' : d_relu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La passe en avant\n",
    "On y va pour le calcul du modèle, et on commence par la passe en avant.\n",
    "\n",
    "D'après les formules, on a besoin de calculer Z et A pour chaque couche, et au passage on aura besoin des Z et A correspondants lors de la marche arrière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Passe en avant : 1 couche - on utilise le dictionnaire de fonctions\n",
    "def layer_forward_pass(X, W, b, activation):\n",
    "    Z = np.dot(W, X) + b\n",
    "    A = act_functions[activation](Z)\n",
    "    return Z, A\n",
    "\n",
    "# Passe en avant : toutes les couches\n",
    "def model_forward_pass(X, activations, parameters):\n",
    "    result = {}\n",
    "    result['A0'] = X\n",
    "    # Entrée de la première couche: X\n",
    "    A = X\n",
    "    for i in range(1, len(activations) + 1):\n",
    "        # Pour chaque couche, une passe en avant. Les W et b viennent de parameters\n",
    "        Z_next, A_next = layer_forward_pass(A, parameters['W' + str(i)], parameters['b' + str(i)], activations[i-1])\n",
    "        result['Z' + str(i)] = Z_next\n",
    "        result['A' + str(i)] = A_next\n",
    "        A = A_next\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La passe en arrière\n",
    "On va maintenant calculer tous les gradients à partir du gradient de A sur la couche dont on vient, ainsi que Z, A et W de la couche considérée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Passe en arrière : 1 couche - on utilise le dictionnaire de dérivées\n",
    "def layer_backward_pass(dA, Z, A_prev, W, activation):\n",
    "    dZ = dA * act_derivates[activation](Z)\n",
    "    dW = np.dot(dZ, A_prev.T)\n",
    "    db = np.sum(dZ, axis=1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    return dW, db, dA_prev\n",
    "\n",
    "# Passe en arrière : toutes les couches\n",
    "def model_backward_pass(dA_last, parameters, forward_pass_results, activations):\n",
    "    gradients = {}\n",
    "    dA = dA_last\n",
    "    for i in range(len(activations), 0, -1):\n",
    "        dW, db, dA_prev = layer_backward_pass(dA,\n",
    "                                              forward_pass_results['Z' + str(i)],\n",
    "                                              forward_pass_results['A' + str(i-1)],\n",
    "                                              parameters['W' + str(i)],\n",
    "                                              activations[i-1])\n",
    "        gradients['dW' + str(i)] = dW\n",
    "        gradients['db' + str(i)] = db\n",
    "        dA = dA_prev\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle\n",
    "Il ne reste plus qu'à faire la descente en elle-même.\n",
    "* On initialise tous les W et tous les b\n",
    "* On boucle \n",
    "  * On calcule tous les Z et tous les A\n",
    "  * On calcule dA final\n",
    "  * On remonte tous les dZ, dA, dW et dB\n",
    "  * On descent les gradients dW et dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(X, Y, layer_dimensions, layer_activations,\n",
    "               learning_rate = 0.01, epochs = 10, batch_size = 64,\n",
    "               show_cost = False):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    #Nombre de couches - hors celle des entrées\n",
    "    l = len(layer_dimensions)-1\n",
    "    \n",
    "    # Création de tous les paramètres\n",
    "    # A chaque étape, W a pour dimensions \"nb neurones de la couche\" x \"nb entrées\"\n",
    "    # Et b est un vecteur, une valeur par neurone\n",
    "    parameters = {}\n",
    "    for i in range(1, l+1):\n",
    "        parameters['W' + str(i)] = np.random.randn(layer_dimensions[i], layer_dimensions[i-1]) * 0.01\n",
    "        parameters['b' + str(i)] = np.zeros((layer_dimensions[i], 1))\n",
    "    \n",
    "    costs = []\n",
    "    # Apprentissage\n",
    "    for e in range(epochs):\n",
    "        for s in range(0, m, batch_size):\n",
    "            x_batch = X[:, s:s+batch_size]\n",
    "            y_batch = Y[:, s:s+batch_size]\n",
    "    \n",
    "            # Passe en avant\n",
    "            forward_pass_results = model_forward_pass(x_batch, layer_activations, parameters)\n",
    "            \n",
    "            # Calcul de la dérivée du coût par rapport au dernier A\n",
    "            A_last = forward_pass_results['A' + str(l)]\n",
    "            dA_last = -(np.divide(y_batch, A_last) - np.divide(1 - y_batch, 1 - A_last))/x_batch.shape[1]\n",
    "\n",
    "            # Calcul des gradients - passe en arrière\n",
    "            gradients = model_backward_pass(dA_last, parameters, forward_pass_results, layer_activations)\n",
    "            \n",
    "            # Descente de gradient\n",
    "            for i in range(1, l+1):\n",
    "                parameters['W' + str(i)] -= learning_rate * gradients['dW' + str(i)]\n",
    "                parameters['b' + str(i)] -= learning_rate * gradients['db' + str(i)]\n",
    "        \n",
    "        # Un peu de debug\n",
    "        model_result = model_forward_pass(X, layer_activations, parameters)['A' + str(l)]\n",
    "        cost = np.squeeze(-np.sum(np.log(model_result) * Y + np.log(1 - model_result) * (1-Y))/m)\n",
    "        costs.append(cost)\n",
    "        if show_cost : print('Epoch #%i: %s' % (e+1, cost))\n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retour à la mise en situation\n",
    "\n",
    "### Chargement des données\n",
    "\n",
    "On continue avec le dataset de Yann Le Cun http://yann.lecun.com/exdb/mnist/ (images 28x28, 60.000 données d'entrainement et 10.000 données de validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file): \n",
    "    data = np.load(file)\n",
    "    return data['x'], data['y']\n",
    "\n",
    "x_train, y_train = load('data/d09_train_data.npz')\n",
    "x_test , y_test  = load('data/d09_test_data.npz')\n",
    "\n",
    "mus    = x_train.mean(axis = 0, keepdims = True)\n",
    "sigmas = x_train.std (axis = 0, keepdims = True) + 1e-9\n",
    "\n",
    "x_train_norm = (x_train-mus)/sigmas\n",
    "x_test_norm  = (x_test -mus)/sigmas\n",
    "\n",
    "y_train_mat = (y_train == np.arange(10)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allez, c'est parti. On va essayer par exemple (au pif) \"tanh 50 / sigmoid 25 / sigmoid 10\" sur 30 époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: 2.30543242166822\n",
      "Epoch #2: 0.8672230396771443\n",
      "Epoch #3: 0.5402521350775323\n",
      "Epoch #4: 0.4020369615764879\n",
      "Epoch #5: 0.3275815333298787\n",
      "Epoch #6: 0.27666591760091486\n",
      "Epoch #7: 0.2396338458387329\n",
      "Epoch #8: 0.21253026251026488\n",
      "Epoch #9: 0.19252387304390495\n",
      "Epoch #10: 0.17572010648636466\n",
      "Epoch #11: 0.16278958540674465\n",
      "Epoch #12: 0.1488421702617406\n",
      "Epoch #13: 0.1365402813484844\n",
      "Epoch #14: 0.12734935170992287\n",
      "Epoch #15: 0.11824495832867164\n",
      "Epoch #16: 0.11030037387666043\n",
      "Epoch #17: 0.103274526001583\n",
      "Epoch #18: 0.09714845430784734\n",
      "Epoch #19: 0.0913995686033537\n",
      "Epoch #20: 0.08535739959465743\n",
      "Epoch #21: 0.08057645151848615\n",
      "Epoch #22: 0.07478317718782729\n",
      "Epoch #23: 0.07106743845405625\n",
      "Epoch #24: 0.06712220945939042\n",
      "Epoch #25: 0.06337991778373567\n",
      "Epoch #26: 0.059884086943492086\n",
      "Epoch #27: 0.057084094023103764\n",
      "Epoch #28: 0.054317420381163925\n",
      "Epoch #29: 0.05180229404945984\n",
      "Epoch #30: 0.04877062957830094\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "epochs = 30\n",
    "activations = ['tanh', 'sigmoid', 'sigmoid']\n",
    "\n",
    "params, costs = train_model(x_train_norm.T, y_train_mat.T, [28*28, 50, 25, 10], activations,\n",
    "                            epochs = epochs, learning_rate = 0.1, show_cost = True)\n",
    "\n",
    "plot.plot(range(epochs), costs)\n",
    "plot.title('Cost, by epochs')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sympa. On va voir le résultat maintenant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set : 99.618333%\n",
      "Accuracy on test set : 95.160000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-db26018beedf>:3: RuntimeWarning: overflow encountered in exp\n",
      "  def tanh(x): return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
      "<ipython-input-5-db26018beedf>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  def tanh(x): return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "def accuracy(x, y, params, layer_activations):\n",
    "    results = np.argmax(model_forward_pass(x, layer_activations, params)['A'+str(len(layer_activations))], axis = 0)\n",
    "    return np.mean(results == y)\n",
    "\n",
    "print('Accuracy on training set : %f%%' % (100*accuracy(x_train_norm.T, y_train.T, params, activations)))\n",
    "print('Accuracy on test set : %f%%'     % (100*accuracy(x_test_norm.T , y_test.T , params, activations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**99.6%** au training !!!\n",
    "\n",
    "Bon par contre *que* 95% au test.\n",
    "\n",
    "Ca signifie un gros overfit puisqu'on a une grosse variance. On a plusieurs manière de traiter ça, on les verra plus tard, mais aussi il faut savoir que plus le modèle est complexe (nombre de couches, nombre de neurones), plus on est sujet à l'overfit : le modèle a toute la liberté qu'il souhaite pour essayer de coller aux données d'entrainement. On essaye un autre modèle \"relu 50 / relu 25 / sigmoide 10\" par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: 3.2195483867992793\n",
      "Epoch #2: 2.0287953695902634\n",
      "Epoch #3: 1.2126691928430533\n",
      "Epoch #4: 0.8336738098191159\n",
      "Epoch #5: 0.5623689268493152\n",
      "Epoch #6: 0.4555980061721843\n",
      "Epoch #7: 0.39161707515738664\n",
      "Epoch #8: 0.3469891733366317\n",
      "Epoch #9: 0.3138278944290432\n",
      "Epoch #10: 0.2879912661898643\n",
      "Epoch #11: 0.2670224230888944\n",
      "Epoch #12: 0.24939292249481787\n",
      "Epoch #13: 0.23433969160319695\n",
      "Epoch #14: 0.221318233683586\n",
      "Epoch #15: 0.2099040925033945\n",
      "Epoch #16: 0.19943010551131396\n",
      "Epoch #17: 0.1899812082312572\n",
      "Epoch #18: 0.1814930746600185\n",
      "Epoch #19: 0.17359656460343328\n",
      "Epoch #20: 0.16625734854894347\n",
      "Epoch #21: 0.15958209107379936\n",
      "Epoch #22: 0.1532596114878994\n",
      "Epoch #23: 0.14738682595420918\n",
      "Epoch #24: 0.14180338078302335\n",
      "Epoch #25: 0.13659951420139718\n",
      "Epoch #26: 0.13155587558984533\n",
      "Epoch #27: 0.12692951793706558\n",
      "Epoch #28: 0.12238802168322196\n",
      "Epoch #29: 0.11819243337864467\n",
      "Epoch #30: 0.11416090553141027\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "epochs = 30\n",
    "activations = ['relu', 'relu', 'sigmoid']\n",
    "\n",
    "params, costs = train_model(x_train_norm.T, y_train_mat.T, [28*28, 50, 25, 10], activations,\n",
    "                            epochs = epochs, learning_rate = 0.01, show_cost = True)\n",
    "\n",
    "plot.plot(range(epochs), costs)\n",
    "plot.title('Cost, by epochs')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set : 98.576667%\n",
      "Accuracy on test set : 96.910000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-db26018beedf>:2: RuntimeWarning: overflow encountered in exp\n",
      "  def sigmoid(x) : return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training set : %f%%' % (100*accuracy(x_train_norm.T, y_train.T, params, activations)))\n",
    "print('Accuracy on test set : %f%%'     % (100*accuracy(x_test_norm.T , y_test.T , params, activations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait *un poil* moins bien sur le jeu d'entrainement mais enfin c'est toujours du 98.57%, et on fait quasiment du 97% sur le jeu de test, ce qui est sensiblement mieux !\n",
    "\n",
    "Voilà, donc un peu plus de biais mais un peu moins de variance sur ce modèle. Et si la métrique qu'on retient est la précision, alors le second modèle est un peu meilleur.\n",
    "\n",
    "\n",
    "## Quelques remarques\n",
    "\n",
    "### L'importance du jeu de dev\n",
    "Quand on dit \"le modèle avec deux ReLUs fonctionne mieux que celui avec tanh + sigmoid\", c'est fortement biaisé : la vérité est que **sur le jeu de test qu'on a à disposition**, ce modèle fait mieux.\n",
    "\n",
    "Autrement dit, on \"entraîne\" l'hyper-paramètre \"structure du réseau\" pour minimiser une fonction de coût (celle sur le jeu de test) !\n",
    "\n",
    "Et de la même manière qu'on valide le résultat de l'entrainement sur des données inconnues, il faudrait faire pareil pour cet ajustement de structure.\n",
    "\n",
    "En gros, il faudrait :\n",
    "* un jeu d'entrainement comme le notre\n",
    "* un jeu de dev, qui nous permet de mieux développer notre modèle : quelle est la meilleure structure, la meilleure régularisation, etc... une fois un modèle entraîné, on compare les performances avec un jeu de données dédié.\n",
    "* un jeu de test, qui nous permet, une fois notre meilleur modèle trouvé, de regarder sa performance \"globale\".\n",
    "\n",
    "### Extension du système\n",
    "Pour intégrer une nouvelle fonction d'activation, rien de plus simple, il suffit d'avoir la fonction souhaitée et sa dérivée, et de les ajouter aux dictionnaires correspondants.\n",
    "\n",
    "### Étapes suivantes\n",
    "Il y a pas mal de choses supplémentaires à faire, pour limiter l'overfit par exemple (un peu de régulation) et des techniques avancées pour optimiser la convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
